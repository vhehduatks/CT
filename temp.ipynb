{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cpu].\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device ='cpu'\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197 1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 5, 7, 8, 4, 3, 9])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df=pd.read_csv('winequalityN.csv')\n",
    "wine_target=wine_df['quality']\n",
    "wine_data=wine_df.drop(columns=['quality'])\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(wine_data,wine_target,test_size=0.2)\n",
    "print(len(train_data),len(test_data))\n",
    "wine_target.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\tdef __init__(self,mode):\n",
    "\t\twine=pd.read_csv('winequalityN.csv')\n",
    "\t\twine_target=wine_df['quality']\n",
    "\t\twine_data=wine_df.drop(columns=['type','quality'])\n",
    "\t\ttrain_data,test_data,train_target,test_target=train_test_split(wine_data,wine_target,test_size=0.2)\n",
    "\t\tif mode=='Train':\n",
    "\t\t\tself.X=train_data\n",
    "\t\t\tself.y=train_target\n",
    "\t\telif mode=='Test':\n",
    "\t\t\tself.X=test_data\n",
    "\t\t\tself.y=test_target\n",
    "\t\telse:\n",
    "\t\t\traise Exception\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\tlen_dataset = None\n",
    "\t\tlen_dataset=len(self.X)\n",
    "\n",
    "\t\treturn len_dataset\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tX=self.X.loc[idx].to_numpy(dtype='float')\n",
    "\t\ty=self.y.loc[idx]\n",
    "\t\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([7.000e+00, 2.700e-01, 3.600e-01, 2.070e+01, 4.500e-02, 4.500e+01,\n",
      "       1.700e+02, 1.001e+00, 3.000e+00, 4.500e-01, 8.800e+00]), 6)\n"
     ]
    }
   ],
   "source": [
    "train_dataset=WineDataset('Train')\n",
    "print(train_dataset[0])\n",
    "train_iter=DataLoader(train_dataset,batch_size=1,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptronClass(nn.Module):\n",
    "\n",
    "    def __init__(self,name='mlp',xdim=11,hdim=10,ydim=7):\n",
    "        super(MultiLayerPerceptronClass,self).__init__()\n",
    "        self.name = name\n",
    "        self.xdim = xdim\n",
    "        self.hdim = hdim\n",
    "        self.ydim = ydim\n",
    "        self.lin_1 = nn.Linear(\n",
    "\t\t\tself.xdim,\n",
    "\t\t\tself.hdim\n",
    "        )\n",
    "        self.lin_2 = nn.Linear(\n",
    "\t\t\tself.hdim,\n",
    "\t\t\tself.ydim\n",
    "        )\n",
    "        self.init_param() # initialize parameters\n",
    "        \n",
    "    def init_param(self):\n",
    "        nn.init.kaiming_normal_(self.lin_1.weight)\n",
    "        nn.init.zeros_(self.lin_1.bias)\n",
    "        nn.init.kaiming_normal_(self.lin_2.weight)\n",
    "        nn.init.zeros_(self.lin_2.bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        net = x\n",
    "        net = self.lin_1(net)\n",
    "        net = F.relu(net)\n",
    "        net = self.lin_2(net)\n",
    "        return net\n",
    "\n",
    "M = MultiLayerPerceptronClass().to(device)\n",
    "loss = nn.MSELoss()\n",
    "optm = optim.Adam(M.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0000e+00, 2.7000e-01, 3.6000e-01, 2.0700e+01, 4.5000e-02, 4.5000e+01,\n",
      "         1.7000e+02, 1.0010e+00, 3.0000e+00, 4.5000e-01, 8.8000e+00]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/temp.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_in,batch_out \u001b[39min\u001b[39;00m train_iter:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000006vscode-remote?line=6'>7</a>\u001b[0m \t\u001b[39mprint\u001b[39m(batch_in)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000006vscode-remote?line=7'>8</a>\u001b[0m \ty_pred \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39;49mforward(batch_in)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000006vscode-remote?line=8'>9</a>\u001b[0m \tloss_out \u001b[39m=\u001b[39m loss(y_pred,batch_out\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000006vscode-remote?line=9'>10</a>\u001b[0m \toptm\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;32m/opt/ml/temp.ipynb Cell 5'\u001b[0m in \u001b[0;36mMultiLayerPerceptronClass.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000005vscode-remote?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000005vscode-remote?line=27'>28</a>\u001b[0m     net \u001b[39m=\u001b[39m x\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000005vscode-remote?line=28'>29</a>\u001b[0m     net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin_1(net)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000005vscode-remote?line=29'>30</a>\u001b[0m     net \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(net)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241495f737461676573227d/opt/ml/temp.ipynb#ch0000005vscode-remote?line=30'>31</a>\u001b[0m     net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_2(net)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:93\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=91'>92</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=92'>93</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1690\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=1686'>1687</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, tens_ops, \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=1687'>1688</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=1688'>1689</a>\u001b[0m     \u001b[39m# fused op is marginally faster\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=1689'>1690</a>\u001b[0m     ret \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddmm(bias, \u001b[39minput\u001b[39;49m, weight\u001b[39m.\u001b[39;49mt())\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=1690'>1691</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=1691'>1692</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mmatmul(weight\u001b[39m.\u001b[39mt())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "M.init_param() # initialize parameters\n",
    "M.train()\n",
    "EPOCHS,print_every = 10,1\n",
    "for epoch in range(EPOCHS):\n",
    "\tloss_val_sum = 0\n",
    "\tfor batch_in,batch_out in train_iter:\n",
    "\t\tprint(batch_in)\n",
    "\t\ty_pred = M.forward(batch_in).to(device)\n",
    "\t\tloss_out = loss(y_pred,batch_out.to(device))\n",
    "\t\toptm.zero_grad()\n",
    "\n",
    "\t\tloss_out.backward()\n",
    "\n",
    "\t\toptm.step()\n",
    "\n",
    "\t\tloss_val_sum += loss_out\n",
    "\tloss_val_avg = loss_val_sum/len(train_iter)\n",
    "\tprint(loss_val_avg)\n",
    "print (\"Done\")        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
